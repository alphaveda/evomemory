EvoMemory: Enhanced Memory System for LLMs
Overview
EvoMemory is a hybrid memory system designed to exponentially improve Large Language Model (LLM) performance by providing structured, persistent, and adaptive context management. It supports any project type (e.g., software, animation, content creation) through a modular file structure, hybrid storage (local Markdown and cloud JSON), and a dynamic Planning Mode.
Repository Structure

EvoMemory_Structure.md: Core EvoMemory system, including memory structure, workflows, and best practices.
EvoMemory_Planning_Mode.md: Expanded Planning Mode for generating adaptable plans for any project.
.gitignore: Excludes unnecessary files (e.g., node_modules, temporary files).

Setup Instructions

Clone the Repository:git clone https://github.com/YOUR_USERNAME/evomemory.git
cd evomemory


Explore Files:
Read EvoMemory_Structure.md for the full system overview.
Read EvoMemory_Planning_Mode.md for details on the universal Planning Mode.


Integrate with LLMs:
Initialize EvoMemory with evo init (requires a CLI implementation, see below).
Configure cloud syncing with a database like MongoDB.


Future CLI Development:
Implement a Python CLI for memory management (e.g., evo init, evo plan).
See EvoMemory_Planning_Mode.md for pseudocode.



Usage

Use Planning Mode to generate phased plans for any project:
Run planning_mode("task description") (pseudocode in EvoMemory_Planning_Mode.md).
Answer generated questions to refine the plan.
Approve and execute the plan, with memory updates after each phase.


Sync memory to a cloud database for persistent storage.
Integrate with MCP servers for API-driven workflows.

Contributing
Contributions are welcome! Please:

Open issues for bugs or feature requests.
Submit pull requests with clear descriptions.
Follow the best practices in EvoMemory_Structure.md.

License
MIT License Â© 2025
